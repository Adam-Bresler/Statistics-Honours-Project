final_data <- read.csv('data_no_ytd.csv')
final_data <- final_data[, -1]
final_data <- read.csv('data_no_ytd.csv')
data <- read.csv("rolling_average_serve_return.csv")
data <- data[,-1]
#Eventually, add this into loop
colnames(data)[c(10,11)] <- c("average_serve_rating", "average_return_rating")
predictive <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)
predictive2 <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)%>%
select(c(1,10,11))
predictive3 <- predictive[seq(1,52668,2),-c(10,11)]
first_player<-predictive2[seq(1,52668,2),-1]
second_player<-predictive2[seq(2,52668,2),-1]
difference <- first_player-second_player
predictive_dataset <- cbind(predictive3,difference)
rm(predictive, predictive2, predictive3, second_player, first_player, difference)
colnames(predictive_dataset)[c(2,3)] <- c("Player_A", "Player_B")
predictive_dataset$wl <- ifelse(predictive_dataset$wl == 'winner', "Player A", "Player B")
predictive_dataset$wl <- as.factor(predictive_dataset$wl)
# Model fitting --------------------------------------------------------------
ind <- 1:23731
train <- predictive_dataset[ind, ]
test <- predictive_dataset[-ind, ]
set.seed(2020)
mod <- glm(wl ~ average_serve_rating + average_return_rating, data = train, family = binomial)
summary(mod)
plot(sort(predict(mod, type = 'response')), type = "l")
threshold <- 0.3
y.hat <- ifelse(predict(mod, newdata = test, type = 'response') > threshold, "Player A", "Player B")
y.hat[which(is.na(y.hat))]
conf_matrix <- table(y.hat, test$wl)
conf_matrix
sum(diag(conf_matrix))/sum(conf_matrix)
sens <- conf_matrix[2,2]/(conf_matrix[1,2]+conf_matrix[2,2])
spec <- conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[2,1])
# Decision Tree --------------------------------------------------------------
library(tree)
#Super basic, default everything
set.seed(2020)
tree_tennis<- tree(wl ~ average_serve_rating + average_return_rating, data = train, split = 'deviance')
summary(tree_tennis)
tree_tennis
plot(tree_tennis)
text(tree_tennis, cex = 0.9)
yhat<- predict(tree_tennis,  test, type = 'class')
(c_mat <- table(yhat, test$wl))
sum(diag(c_mat))/nrow(test)*100
1 - sum(diag(c_mat))/nrow(test)
# Random Forest --------------------------------------------------------------
#Super basic, default everything
library(randomForest)
set.seed(2020)
rf_tennis <- randomForest(wl ~ average_serve_rating + average_return_rating, data = train,
ntree = 1000, #no mtry argument, keep it defualt
importance = TRUE,
do.trace = 100)
rf_tennis
plot(rf_tennis$err.rate[, 'OOB'], type = 's', xlab = 'Number of trees', ylab = 'OOB error')
rf_pred <- predict(rf_tennis, newdata = test)
table(rf_pred, test$wl)
(rf_err <- mean(rf_pred != test$wl))
# Boosting -------------------------------------------------------------------
library(gbm)
ctrl <- trainControl(method = 'cv', number = 5, verboseIter = T)
gbm_grid <- expand.grid(n.trees = c(250, 500, 1000),
interaction.depth = c(1, 2),
shrinkage = c(0.1, 0.05, 0.01),
n.minobsinnode = 1)
set.seed(2020)
gbm_tennis <- train(wl ~ average_serve_rating + average_return_rating, data = train,
method = 'gbm',
distribution = 'bernoulli',
trControl = ctrl,
verbose = F,
tuneGrid = gbm_grid)
gbm_pred <- predict(gbm_tennis, test)
gbm_cf <- confusionMatrix(gbm_pred, test$wl)
sum(diag(gbm_cf$table))/sum(gbm_cf$table)
# Creating the predictive ----------------------------------------------------
data <- read.csv("rolling_average_serve_return.csv")
setwd("~/GitHub/Statistics-Honours-Project/Data")
setwd("~/GitHub/Statistics-Honours-Project/Data")
# Creating the predictive ----------------------------------------------------
data <- read.csv("rolling_average_serve_return.csv")
data <- data[,-1]
colnames(data)[c(10,11)] <- c("average_serve_rating", "average_return_rating")
predictive <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)
predictive2 <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)%>%
select(c(1,10,11))
predictive3 <- predictive[seq(1,52668,2),-c(10,11)]
first_player<-predictive2[seq(1,52668,2),-1]
second_player<-predictive2[seq(2,52668,2),-1]
difference <- first_player-second_player
predictive_dataset <- cbind(predictive3,difference)
rm(predictive, predictive2, predictive3, second_player, first_player, difference)
colnames(predictive_dataset)[c(2,3)] <- c("Player_A", "Player_B")
predictive_dataset$wl <- ifelse(predictive_dataset$wl == 'winner', "Player A", "Player B")
predictive_dataset$wl <- as.factor(predictive_dataset$wl)
# Model fitting --------------------------------------------------------------
ind <- 1:23731
train <- predictive_dataset[ind, ]
test <- predictive_dataset[-ind, ]
set.seed(2020)
mod <- glm(wl ~ average_serve_rating + average_return_rating, data = train, family = binomial)
summary(mod)
plot(sort(predict(mod, type = 'response')), type = "l")
threshold <- 0.3
y.hat <- ifelse(predict(mod, newdata = test, type = 'response') > threshold, "Player A", "Player B")
y.hat[which(is.na(y.hat))]
conf_matrix <- table(y.hat, test$wl)
conf_matrix
sum(diag(conf_matrix))/sum(conf_matrix)
sens <- conf_matrix[2,2]/(conf_matrix[1,2]+conf_matrix[2,2])
spec <- conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[2,1])
# Decision Tree --------------------------------------------------------------
library(tree)
#Super basic, default everything
set.seed(2020)
tree_tennis<- tree(wl ~ average_serve_rating + average_return_rating, data = train, split = 'deviance')
summary(tree_tennis)
tree_tennis
plot(tree_tennis)
text(tree_tennis, cex = 0.9)
yhat<- predict(tree_tennis,  test, type = 'class')
(c_mat <- table(yhat, test$wl))
sum(diag(c_mat))/nrow(test)*100
1 - sum(diag(c_mat))/nrow(test)
# Random Forest --------------------------------------------------------------
#Super basic, default everything
library(randomForest)
set.seed(2020)
rf_tennis <- randomForest(wl ~ average_serve_rating + average_return_rating, data = train,
ntree = 1000, #no mtry argument, keep it defualt
importance = TRUE,
do.trace = 100)
rf_tennis
plot(rf_tennis$err.rate[, 'OOB'], type = 's', xlab = 'Number of trees', ylab = 'OOB error')
rf_pred <- predict(rf_tennis, newdata = test)
table(rf_pred, test$wl)
(rf_err <- mean(rf_pred != test$wl))
# Boosting -------------------------------------------------------------------
library(gbm)
ctrl <- trainControl(method = 'cv', number = 5, verboseIter = T)
gbm_grid <- expand.grid(n.trees = c(250, 500, 1000),
interaction.depth = c(1, 2),
shrinkage = c(0.1, 0.05, 0.01),
n.minobsinnode = 1)
set.seed(2020)
gbm_tennis <- train(wl ~ average_serve_rating + average_return_rating, data = train,
method = 'gbm',
distribution = 'bernoulli',
trControl = ctrl,
verbose = F,
tuneGrid = gbm_grid)
gbm_pred <- predict(gbm_tennis, test)
gbm_cf <- confusionMatrix(gbm_pred, test$wl)
sum(diag(gbm_cf$table))/sum(gbm_cf$table)
#Eventually, add this into loop
colnames(data)[c(10,11)] <- c("average_serve_rating", "average_return_rating")
predictive <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)
library(dplyr)
library(tidyverse)
library(lubridate)
library(magrittr)
library(caret)
predictive <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)
predictive2 <- data %>%
group_by(Match_ID)%>%arrange(.by_group = TRUE)%>%
select(c(1,10,11))
predictive3 <- predictive[seq(1,52668,2),-c(10,11)]
first_player<-predictive2[seq(1,52668,2),-1]
second_player<-predictive2[seq(2,52668,2),-1]
difference <- first_player-second_player
predictive_dataset <- cbind(predictive3,difference)
rm(predictive, predictive2, predictive3, second_player, first_player, difference)
colnames(predictive_dataset)[c(2,3)] <- c("Player_A", "Player_B")
predictive_dataset$wl <- ifelse(predictive_dataset$wl == 'winner', "Player A", "Player B")
predictive_dataset$wl <- as.factor(predictive_dataset$wl)
# Model fitting --------------------------------------------------------------
ind <- 1:23731
train <- predictive_dataset[ind, ]
test <- predictive_dataset[-ind, ]
set.seed(2020)
mod <- glm(wl ~ average_serve_rating + average_return_rating, data = train, family = binomial)
summary(mod)
plot(sort(predict(mod, type = 'response')), type = "l")
threshold <- 0.3
y.hat <- ifelse(predict(mod, newdata = test, type = 'response') > threshold, "Player A", "Player B")
y.hat[which(is.na(y.hat))]
conf_matrix <- table(y.hat, test$wl)
conf_matrix
sum(diag(conf_matrix))/sum(conf_matrix)
sens <- conf_matrix[2,2]/(conf_matrix[1,2]+conf_matrix[2,2])
spec <- conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[2,1])
# Decision Tree --------------------------------------------------------------
library(tree)
#Super basic, default everything
set.seed(2020)
tree_tennis<- tree(wl ~ average_serve_rating + average_return_rating, data = train, split = 'deviance')
summary(tree_tennis)
tree_tennis
plot(tree_tennis)
text(tree_tennis, cex = 0.9)
yhat<- predict(tree_tennis,  test, type = 'class')
(c_mat <- table(yhat, test$wl))
sum(diag(c_mat))/nrow(test)*100
1 - sum(diag(c_mat))/nrow(test)
# Random Forest --------------------------------------------------------------
#Super basic, default everything
library(randomForest)
set.seed(2020)
rf_tennis <- randomForest(wl ~ average_serve_rating + average_return_rating, data = train,
ntree = 1000, #no mtry argument, keep it defualt
importance = TRUE,
do.trace = 100)
rf_tennis
plot(rf_tennis$err.rate[, 'OOB'], type = 's', xlab = 'Number of trees', ylab = 'OOB error')
rf_pred <- predict(rf_tennis, newdata = test)
table(rf_pred, test$wl)
(rf_err <- mean(rf_pred != test$wl))
# Boosting -------------------------------------------------------------------
library(gbm)
ctrl <- trainControl(method = 'cv', number = 5, verboseIter = T)
gbm_grid <- expand.grid(n.trees = c(250, 500, 1000),
interaction.depth = c(1, 2),
shrinkage = c(0.1, 0.05, 0.01),
n.minobsinnode = 1)
set.seed(2020)
gbm_tennis <- train(wl ~ average_serve_rating + average_return_rating, data = train,
method = 'gbm',
distribution = 'bernoulli',
trControl = ctrl,
verbose = F,
tuneGrid = gbm_grid)
gbm_pred <- predict(gbm_tennis, test)
gbm_cf <- confusionMatrix(gbm_pred, test$wl)
sum(diag(gbm_cf$table))/sum(gbm_cf$table)
View(data)
View(predictive_dataset)
View(train)
View(data)
# Read in data ---------------------------------------------------------------
library(readr)
colnames_match_stats <- c("match_id",
"tourney_slug",
"match_stats_url_suffix",
"match_time",
"match_duration",
"winner_slug",
"winner_serve_rating",
"winner_aces",
"winner_double_faults",
"winner_first_serves_in",
"winner_first_serves_total",
"winner_first_serve_points_won",
"winner_first_serve_points_total",
"winner_second_serve_points_won",
"winner_second_serve_points_total",
"winner_break_points_saved",
"winner_break_points_serve_total",
"winner_service_games_played",
"winner_return_rating",
"winner_first_serve_return_won",
"winner_first_serve_return_total",
"winner_second_serve_return_won",
"winner_second_serve_return_total",
"winner_break_points_converted",
"winner_break_points_return_total",
"winner_return_games_played",
"winner_service_points_won",
"winner_service_points_total",
"winner_return_points_won",
"winner_return_points_total",
"winner_total_points_won",
"winner_total_points_total",
"loser_slug",
"loser_serve_rating",
"loser_aces",
"loser_double_faults",
"loser_first_serves_in",
"loser_first_serves_total",
"loser_first_serve_points_won",
"loser_first_serve_points_total",
"loser_second_serve_points_won",
"loser_second_serve_points_total",
"loser_break_points_saved",
"loser_break_points_serve_total",
"loser_service_games_played",
"loser_return_rating",
"loser_first_serve_return_won",
"loser_first_serve_return_total",
"loser_second_serve_return_won",
"loser_second_serve_return_total",
"loser_break_points_converted",
"loser_break_points_return_total",
"loser_return_games_played",
"loser_service_points_won",
"loser_service_points_total",
"loser_return_points_won",
"loser_return_points_total",
"loser_total_points_won",
"loser_total_points_total")
colnames_match_scores <- c("tourney_year_id",
"tourney_order",
"tourney_name",
"tourney_slug",
"tourney_url_suffix",
"start_date",
"start_year",
"start_month",
"start_day",
"end_date",
"end_year",
"end_month",
"end_day",
"currency",
"prize_money",
"match_index",
"tourney_round_name",
"round_order",
"match_order",
"winner_name",
"winner_player_id",
"winner_slug",
"loser_name",
"loser_player_id",
"loser_slug",
"winner_seed",
"loser_seed",
"match_score_tiebreaks",
"winner_sets_won",
"loser_sets_won",
"winner_games_won",
"loser_games_won",
"winner_tiebreaks_won",
"loser_tiebreaks_won",
"match_id",
"match_stats_url_suffix")
colnames_tourney_stats<-c("tourney_year_id",
"tourney_order",
"tourney_type",
"tourney_name",
"tourney_id",
"tourney_slug",
"tourney_location",
"tourney_date",
"year",
"tourney_month",
"tourney_day",
"tourney_singles_draw",
"tourney_doubles_draw",
"tourney_conditions",
"tourney_surface",
"tourney_fin_commit_raw",
"currency",
"tourney_fin_commit",
"tourney_url_suffix",
"singles_winner_name",
"singles_winner_url",
"singles_winner_player_slug",
"singles_winner_player_id",
"doubles_winner_1_name",
"doubles_winner_1_url",
"doubles_winner_1_player_slug",
"doubles_winner_1_player_id",
"doubles_winner_2_name",
"doubles_winner_2_url",
"doubles_winner_2_player_slug",
"doubles_winner_2_player_id")
tourney_stats_2010_2019 <- read_csv("tournaments_2010-2019.csv", col_names = colnames_tourney_stats)
match_stats_2019 <- read_csv("match_stats_2019.csv", col_names = colnames_match_stats)
match_stats_2018 <- read_csv("match_stats_2018.csv", col_names = colnames_match_stats)
match_stats_2017 <- read_csv("match_stats_2017.csv", col_names = colnames_match_stats)
match_stats_2016 <- read_csv("match_stats_2016.csv", col_names = colnames_match_stats)
match_stats_2015 <- read_csv("match_stats_2015.csv", col_names = colnames_match_stats)
match_stats_2014 <- read_csv("match_stats_2014.csv", col_names = colnames_match_stats)
match_stats_2013 <- read_csv("match_stats_2013.csv", col_names = colnames_match_stats)
match_stats_2012 <- read_csv("match_stats_2012.csv", col_names = colnames_match_stats)
match_stats_2011 <- read_csv("match_stats_2011.csv", col_names = colnames_match_stats)
match_stats_2010 <- read_csv("match_stats_2010.csv", col_names = colnames_match_stats)
match_stats <- rbind(match_stats_2010, match_stats_2011, match_stats_2012,
match_stats_2013, match_stats_2014, match_stats_2015,
match_stats_2016, match_stats_2017, match_stats_2018,
match_stats_2019)
rm(match_stats_2010, match_stats_2011, match_stats_2012,
match_stats_2013, match_stats_2014, match_stats_2015,
match_stats_2016, match_stats_2017, match_stats_2018,
match_stats_2019)
match_scores <- read_csv("match_scores_2010-2019.csv", col_names = colnames_match_scores)
View(match_stats)
View(match_scores)
